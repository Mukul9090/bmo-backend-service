name: CI/CD Pipeline - Deploy to Kubernetes

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:

env:
  DOCKER_IMAGE: mukul1599/backend-service
  DOCKER_TAG: latest
  K8S_CLUSTER_HOT_CONTEXT: hot-cluster
  K8S_CLUSTER_STANDBY_CONTEXT: standby-cluster
  HAPROXY_CLUSTER_CONTEXT: hot-cluster
  REPLICAS: 2

jobs:
  build-and-push:
    name: Build and Push Docker Image
    runs-on: [self-hosted, macOS, ARM64]
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      
      - name: Test Docker Hub connectivity
        run: |
          for i in {1..3}; do
            curl -s --max-time 10 https://registry-1.docker.io/v2/ > /dev/null && exit 0 || sleep 5
          done
          exit 1
        timeout-minutes: 2

      - name: Login and Build
        uses: docker/login-action@v3
        timeout-minutes: 10
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push
        uses: docker/build-push-action@v5
        timeout-minutes: 45
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy to Kubernetes
    runs-on: [self-hosted, macOS, ARM64]
    needs: build-and-push
    if: github.event_name != 'pull_request'
    steps:
      - uses: actions/checkout@v4

      - name: Detect cluster contexts
        id: detect-contexts
        run: |
          # Get available contexts
          AVAILABLE_CONTEXTS=$(kubectl config get-contexts -o name 2>/dev/null || echo "")
          CURRENT_CONTEXT=$(kubectl config current-context 2>/dev/null || echo "")
          
          echo "Available contexts: $AVAILABLE_CONTEXTS"
          echo "Current context: $CURRENT_CONTEXT"
          
          # Check if specified contexts exist, otherwise use current context
          if kubectl config get-contexts ${{ env.K8S_CLUSTER_HOT_CONTEXT }} &>/dev/null; then
            HOT_CTX="${{ env.K8S_CLUSTER_HOT_CONTEXT }}"
            echo "‚úÖ Using hot context: $HOT_CTX"
          else
            HOT_CTX="${CURRENT_CONTEXT:-minikube}"
            echo "‚ö†Ô∏è  Hot context '${{ env.K8S_CLUSTER_HOT_CONTEXT }}' not found, using: $HOT_CTX"
          fi
          
          if kubectl config get-contexts ${{ env.K8S_CLUSTER_STANDBY_CONTEXT }} &>/dev/null; then
            STANDBY_CTX="${{ env.K8S_CLUSTER_STANDBY_CONTEXT }}"
            echo "‚úÖ Using standby context: $STANDBY_CTX"
          else
            STANDBY_CTX="${CURRENT_CONTEXT:-minikube}"
            echo "‚ö†Ô∏è  Standby context '${{ env.K8S_CLUSTER_STANDBY_CONTEXT }}' not found, using: $STANDBY_CTX"
          fi
          
          if kubectl config get-contexts ${{ env.HAPROXY_CLUSTER_CONTEXT }} &>/dev/null; then
            HAPROXY_CTX="${{ env.HAPROXY_CLUSTER_CONTEXT }}"
            echo "‚úÖ Using HAProxy context: $HAPROXY_CTX"
          else
            HAPROXY_CTX="${CURRENT_CONTEXT:-minikube}"
            echo "‚ö†Ô∏è  HAProxy context '${{ env.HAPROXY_CLUSTER_CONTEXT }}' not found, using: $HAPROXY_CTX"
          fi
          
          echo "hot_context=$HOT_CTX" >> $GITHUB_OUTPUT
          echo "standby_context=$STANDBY_CTX" >> $GITHUB_OUTPUT
          echo "haproxy_context=$HAPROXY_CTX" >> $GITHUB_OUTPUT

      - name: Deploy to clusters
        run: |
          HOT_CTX="${{ steps.detect-contexts.outputs.hot_context }}"
          STANDBY_CTX="${{ steps.detect-contexts.outputs.standby_context }}"
          HAPROXY_CTX="${{ steps.detect-contexts.outputs.haproxy_context }}"
          
          # Deploy hot cluster
          kubectl create configmap backend-config --from-literal=CLUSTER_ROLE=hot --context=$HOT_CTX -n default --dry-run=client -o yaml | kubectl apply --context=$HOT_CTX -f -
          sed "s|image: ${{ env.DOCKER_IMAGE }}$|image: ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}|" k8s/cluster-hot/deployment.yaml | kubectl apply --context=$HOT_CTX -f -
          kubectl apply --context=$HOT_CTX -f k8s/cluster-hot/service.yaml
          
          # Deploy standby cluster
          kubectl create configmap backend-config --from-literal=CLUSTER_ROLE=standby --context=$STANDBY_CTX -n default --dry-run=client -o yaml | kubectl apply --context=$STANDBY_CTX -f -
          sed "s|image: ${{ env.DOCKER_IMAGE }}$|image: ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}|" k8s/cluster-standby/deployment.yaml | kubectl apply --context=$STANDBY_CTX -f -
          kubectl apply --context=$STANDBY_CTX -f k8s/cluster-standby/service.yaml
          
          # Get external IPs with better fallback logic
          sleep 10
          
          # Try to get LoadBalancer IP first, then NodePort, then internal service DNS
          HOT_IP=$(kubectl get svc backend-service --context=$HOT_CTX -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
          if [ -z "$HOT_IP" ]; then
            # Try to get node IP for NodePort access
            HOT_IP=$(kubectl get nodes --context=$HOT_CTX -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null)
          fi
          if [ -z "$HOT_IP" ]; then
            # Fallback to internal service DNS (for single-cluster setup)
            HOT_IP="backend-service.cluster-hot.svc.cluster.local"
            echo "‚ö†Ô∏è  Using internal DNS for hot cluster: $HOT_IP"
          else
            echo "‚úÖ Using IP for hot cluster: $HOT_IP"
          fi
          
          STANDBY_IP=$(kubectl get svc backend-service --context=$STANDBY_CTX -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
          if [ -z "$STANDBY_IP" ]; then
            STANDBY_IP=$(kubectl get nodes --context=$STANDBY_CTX -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null)
          fi
          if [ -z "$STANDBY_IP" ]; then
            STANDBY_IP="backend-service.cluster-standby.svc.cluster.local"
            echo "‚ö†Ô∏è  Using internal DNS for standby cluster: $STANDBY_IP"
          else
            echo "‚úÖ Using IP for standby cluster: $STANDBY_IP"
          fi
          
          # Validate IPs are not empty or "localhost"
          if [ "$HOT_IP" = "localhost" ] || [ -z "$HOT_IP" ]; then
            echo "‚ùå Invalid HOT_IP: $HOT_IP, using internal DNS fallback"
            HOT_IP="backend-service.cluster-hot.svc.cluster.local"
          fi
          
          if [ "$STANDBY_IP" = "localhost" ] || [ -z "$STANDBY_IP" ]; then
            echo "‚ùå Invalid STANDBY_IP: $STANDBY_IP, using internal DNS fallback"
            STANDBY_IP="backend-service.cluster-standby.svc.cluster.local"
          fi
          
          echo "Final HOT_IP: $HOT_IP"
          echo "Final STANDBY_IP: $STANDBY_IP"
          
          # Update and deploy HAProxy with validated IPs
          # Add port 80 for all IPs/DNS (HAProxy config expects format: server name IP:port)
          if [[ "$HOT_IP" == *":"* ]]; then
            # IP already has port, use as-is
            HOT_SERVER="${HOT_IP}"
          else
            # Add port 80
            HOT_SERVER="${HOT_IP}:80"
          fi
          
          if [[ "$STANDBY_IP" == *":"* ]]; then
            STANDBY_SERVER="${STANDBY_IP}"
          else
            STANDBY_SERVER="${STANDBY_IP}:80"
          fi
          
          echo "Deploying HAProxy with:"
          echo "  Hot server: $HOT_SERVER"
          echo "  Standby server: $STANDBY_SERVER"
          
          sed "s|<HOT_CLUSTER_EXTERNAL_IP>|${HOT_SERVER}|g" k8s/haproxy/configmap.yaml | sed "s|<STANDBY_CLUSTER_EXTERNAL_IP>|${STANDBY_SERVER}|g" | kubectl apply --context=$HAPROXY_CTX -f -
          kubectl apply --context=$HAPROXY_CTX -f k8s/haproxy/deployment.yaml
          kubectl apply --context=$HAPROXY_CTX -f k8s/haproxy/service.yaml

      - name: Wait for deployments
        run: |
          HOT_CTX="${{ steps.detect-contexts.outputs.hot_context }}"
          STANDBY_CTX="${{ steps.detect-contexts.outputs.standby_context }}"
          HAPROXY_CTX="${{ steps.detect-contexts.outputs.haproxy_context }}"
          
          kubectl wait --for=condition=available --timeout=300s deployment/backend-service --context=$HOT_CTX -n default || true
          kubectl wait --for=condition=available --timeout=300s deployment/backend-service --context=$STANDBY_CTX -n default || true
          kubectl wait --for=condition=available --timeout=300s deployment/haproxy --context=$HAPROXY_CTX || true

      - name: Setup persistent HAProxy port-forward
        run: |
          HAPROXY_CTX="${{ steps.detect-contexts.outputs.haproxy_context }}"
          
          # Verify HAProxy service exists
          if ! kubectl get svc haproxy --context=$HAPROXY_CTX &>/dev/null; then
            echo "‚ùå HAProxy service not found, skipping port-forward setup" >> $GITHUB_STEP_SUMMARY
            echo "HAProxy service may not be deployed yet" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          
          # Create bin directory if it doesn't exist
          mkdir -p ~/bin
          
          # Stop any existing port-forwards
          pkill -f "kubectl port-forward.*haproxy" || true
          pkill -f "keep-haproxy-forward" || true
          sleep 2
          
          # Create persistent port-forward script
          cat > ~/bin/keep-haproxy-forward.sh << EOF
          #!/bin/bash
          while true; do
            kubectl port-forward --context=$HAPROXY_CTX svc/haproxy 9090:9090 2>&1 | tee -a /tmp/haproxy-portforward.log
            echo "Port-forward disconnected, reconnecting in 5 seconds..." >> /tmp/haproxy-portforward.log
            sleep 5
          done
          EOF
          
          chmod +x ~/bin/keep-haproxy-forward.sh
          
          # Start the persistent port-forward in background
          nohup ~/bin/keep-haproxy-forward.sh > /dev/null 2>&1 &
          
          # Wait and verify port-forward is actually working
          echo "Waiting for HAProxy port-forward to be ready..."
          PORT_READY=false
          for i in {1..30}; do
            if curl -s -f http://localhost:9090/healthz > /dev/null 2>&1; then
              echo "‚úÖ HAProxy port-forward is ready!" >> $GITHUB_STEP_SUMMARY
              echo "‚úÖ HAProxy accessible at http://localhost:9090" >> $GITHUB_STEP_SUMMARY
              PORT_READY=true
              break
            fi
            sleep 2
          done
          
          if [ "$PORT_READY" = "false" ]; then
            echo "‚ö†Ô∏è  HAProxy port-forward not ready after 60 seconds" >> $GITHUB_STEP_SUMMARY
            echo "Checking port-forward logs:" >> $GITHUB_STEP_SUMMARY
            tail -20 /tmp/haproxy-portforward.log >> $GITHUB_STEP_SUMMARY 2>&1 || echo "No logs available" >> $GITHUB_STEP_SUMMARY
            echo "Checking if HAProxy pod is running:" >> $GITHUB_STEP_SUMMARY
            kubectl get pods --context=$HAPROXY_CTX -l app=haproxy >> $GITHUB_STEP_SUMMARY 2>&1 || true
          fi

      - name: Run basic deployment tests
        run: |
          HOT_CTX="${{ steps.detect-contexts.outputs.hot_context }}"
          STANDBY_CTX="${{ steps.detect-contexts.outputs.standby_context }}"
          
          # Check if test file exists
          if [ ! -f "tests/test_deployment.py" ]; then
            echo "‚ö†Ô∏è  test_deployment.py not found, skipping basic tests" >> $GITHUB_STEP_SUMMARY
            echo "This is expected if test files were removed for production" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          
          # Install requests if not available
          pip3 install --user requests --quiet 2>/dev/null || pip3 install requests --break-system-packages --quiet || true
          
          # Set up port-forwards for direct cluster access
          kubectl port-forward --context=$HOT_CTX svc/backend-service 8080:80 > /dev/null 2>&1 &
          kubectl port-forward --context=$STANDBY_CTX svc/backend-service 8081:80 > /dev/null 2>&1 &
          
          # Verify port-forwards are working
          echo "Waiting for port-forwards to be ready..."
          for i in {1..10}; do
            if curl -s -f http://localhost:8080/healthz > /dev/null 2>&1 && \
               curl -s -f http://localhost:8081/healthz > /dev/null 2>&1; then
              echo "‚úÖ Port-forwards ready"
              break
            fi
            if [ $i -eq 10 ]; then
              echo "‚ö†Ô∏è  Port-forwards not ready after 10 attempts, continuing anyway"
            fi
            sleep 1
          done
          
          # Set environment variables
          export HOT_URL="http://localhost:8080"
          export STANDBY_URL="http://localhost:8081"
          export HAPROXY_URL="http://localhost:9090"
          export PYTHONPATH="${HOME}/Library/Python/3.14/lib/python/site-packages:${PYTHONPATH:-}"
          
          # Run basic tests (non-blocking)
          python3 tests/test_deployment.py || echo "‚ö†Ô∏è  Basic tests had some failures (non-blocking)"

      - name: Run failover tests
        run: |
          HOT_CTX="${{ steps.detect-contexts.outputs.hot_context }}"
          STANDBY_CTX="${{ steps.detect-contexts.outputs.standby_context }}"
          HAPROXY_CTX="${{ steps.detect-contexts.outputs.haproxy_context }}"
          
          # Check if HAProxy port-forward is working
          if ! curl -s -f http://localhost:9090/healthz > /dev/null 2>&1; then
            echo "‚ùå HAProxy not accessible at localhost:9090" >> $GITHUB_STEP_SUMMARY
            echo "Skipping failover tests - HAProxy port-forward may not be ready" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          
          # Check if test file exists
          if [ ! -f "tests/test_failover.py" ]; then
            echo "‚ö†Ô∏è  test_failover.py not found, skipping failover tests" >> $GITHUB_STEP_SUMMARY
            echo "This is expected if test files were removed for production" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi
          
          # Install requests if not available
          pip3 install --user requests --quiet 2>/dev/null || pip3 install requests --break-system-packages --quiet || true
          
          # Set environment variables
          export HAPROXY_URL="http://localhost:9090"
          export NAMESPACE_HOT="default"
          export NAMESPACE_STANDBY="default"
          export PYTHONPATH="${HOME}/Library/Python/3.14/lib/python/site-packages:${PYTHONPATH:-}"
          
          echo "üîÑ Running failover tests..." >> $GITHUB_STEP_SUMMARY
          echo "   - Test 1: Scale hot pods to 0, verify failover to standby" >> $GITHUB_STEP_SUMMARY
          echo "   - Test 2: Scale hot pods back up, verify recovery" >> $GITHUB_STEP_SUMMARY
          
          # Run failover tests (non-blocking for now)
          python3 tests/test_failover.py || echo "‚ö†Ô∏è  Failover tests had some failures (non-blocking)"

      - name: Deployment summary
        run: |
          HOT_CTX="${{ steps.detect-contexts.outputs.hot_context }}"
          STANDBY_CTX="${{ steps.detect-contexts.outputs.standby_context }}"
          HAPROXY_CTX="${{ steps.detect-contexts.outputs.haproxy_context }}"
          
          echo "## üöÄ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "Using contexts - Hot: $HOT_CTX, Standby: $STANDBY_CTX, HAProxy: $HAPROXY_CTX" >> $GITHUB_STEP_SUMMARY
          kubectl get pods --context=$HOT_CTX -n default -l app=backend-service >> $GITHUB_STEP_SUMMARY || true
          kubectl get pods --context=$STANDBY_CTX -n default -l app=backend-service >> $GITHUB_STEP_SUMMARY || true
          kubectl get pods --context=$HAPROXY_CTX -l app=haproxy >> $GITHUB_STEP_SUMMARY || true
